### chapter 3 sensors

自动系统的导航通常采用传感器套件，包括各种不同类型的传感器，包括摄像头、车轮里程表和距离传感器(声纳、雷达和激光雷达)。例如，特斯拉在其先进的驾驶辅助系统Autopilot中使用了多个摄像头、雷达和超声波。融合来自多个传感器的信息，可以利用它们的互补特性，解决单个传感器的局限性，例如，摄像机中丢失的结构信息或距离数据中丢失的颜色信息。


车轮里程表测量车轮的转动，可以用来估计自动驾驶汽车行驶的距离。然而，轮距测量并不能提供完整的车辆姿态(即所有6个自由度)，因此通常与第13章讨论的视觉里程测量或SLAM技术相结合。距离传感器，例如 超生，毫米波雷达，激光雷达，提供关于场景的几何和结构的额外信息。超声波传感器(声纳)发出高频声波，测量声波传播到附近物体的时间。由于声波的速度已知，所以它与物体的距离是由声波的传播时间计算出来的。毫米波雷达和激光雷达的工作原理相同，但使用电磁波和激光光脉冲，而不是声波。由于波长较大，毫米波雷达传感器比激光雷达和声纳的工作距离大，但精度较低。

由于摄像头价格低廉、是被动式传感器，易于部署，因此它们是自动驾驶汽车一个有吸引力的传感器选择，而且一些现有的驾驶辅助系统依赖于摄像头来保持车道或检测行人。现在，我们简要地讨论最主要的摄像机类型，并给出一个估计传感器内外参的标定流程的简短概述。

#### 3.1相机模型

大多数传统相机由一个光圈和一个或多个镜头组成，可以很好地近似针孔相机模型(图3.1)。全景相机允许利用反光镜或特殊镜头显著扩大视场。事件摄像机能够在非常高的时间分辨率下获取强度变化。接下来，我们提供一个全景和事件摄像头的简要概述。关于针孔相机模型和射影几何的深入讨论，请参阅[652,278]。


##### 3.1.1全景相机

在自动驾驶中需要全景视野，以获得关于周围区域的最大信息，以便安全导航。具有360度视场的全景相机(见图3.2)消除了对更多相机或机械可旋转相机的需求，提供了增强的覆盖范围。有不同类型的全景相机。折射率相机结合了一个标准相机与一个特定形状的镜子，如抛物线，双曲线，或椭圆镜，而屈光相机使用纯屈光鱼眼镜头。多屈光相机使用多个相机的重叠的视场，以提供一个完整的球形视场。

Geyer和Daniilidis[248]为所有中心折光系统提供了统一的理论，在文献中称为统一投影模型，并被不同的标定工具箱广泛使用[460,293,292]。Scara muzza和Martinelli[590]提出使用泰勒级数展开来建模成像函数。Mei和Rives[460]改进了[248]的统一投影模型，通过建模畸变来解释现实世界的误差。Scḧonbein等人[598]提出了一种计算开销大的非中心相机模型的快速近似。

全景相机在自动驾驶研究中越来越受欢迎。对于基于特征的应用，如导航、运动估计和建图，一个大的视场可以从汽车周围的所有兴趣点提取和匹配。因此，全景摄像机已成功用于改善车辆的自车运动估计[587]和静态场景的三维重建[597,271]。


##### 3.1.2事件相机

与传统的基于帧的摄像机相反，事件摄像机在微秒分辨率下产生的亮度变化超过预定义阈值的异步事件流，如图3.3所示。事件包括更改的位置、标记和时间戳。由于事件在空间和时间上都是稀疏的，这种表示有可能减少传输和处理需求。高时间分辨率使高反应系统的发展成为可能。

动态活动像素视觉传感器(DAVIS)以固定帧率输出CMOS图像和异步事件，因此结合了两种传感器的优点。Mueggler等人[485]提供了用DAVIS捕获的真实数据和合成数据的数据集，以推动基于事件方法的研究。Binas等人展示了DAVIS驾驶数据集，并演示了转向角度的端到端学习。最近的研究利用DAVIS进行特征跟踪[237]和SLAM[686]，与仅使用单一模态相比，提高了准确性和鲁棒性。
针对各种问题，利用事件传感器的高时间分辨率和异步特性开发了多种方法。这些方法主要集中在无人机的应用上，因为需要非常有效的方法来导航这些系统。在这种情况下，基于事件的摄像机已被用于自我运动估计[484]、同步定位和建图(SLAM)[547]以及寻找特征匹配[226]。最近，基于事件的传感器通过端到端学习转向角度，在自动驾驶车辆中发挥了优势[449]。

#### 3.2标定

几何标定是估计一个或多个传感器的内在和外在参数，以便准确地将三维世界点与二维测量值联系起来的问题。基准标记点和棋盘格通常用于参数估计[784,62,340,9,244]。
自20世纪70年代以来，各种相机校准方法层出不穷。Heikkila和Silven[290]首先考虑了整个标定流程，包括控制点提取、模型拟合和图像校正。他们提出了一个四步程序来获取物理相机模型的参数，并解决补偿图像失真的问题。

现代车辆通常配备多个不同的传感器，目的是提高鲁棒性和覆盖范围。为了满足这类大型传感器套件的需求，已经提出了几种校准程序。早期的方法[784,62]依赖于激光扫描中手动提取兴趣点，而Kassir和Peynot[340]以及Andreasson和Lilienthal[9]提出了第一个完整的自动相机到距离传感器的标定系统。Geiger等人[244]演示了如何自动标定包含两个摄像机和一个距离传感器(如Kinect或Velodyne激光扫描仪)的设置。Heng等人[293]解决了在没有重叠视场的情况下估计多摄像机设备的内外参的问题。Heng等人[292]扩展了这项工作，修改环境的时候，使用地图和自然特征代替基准标记点。