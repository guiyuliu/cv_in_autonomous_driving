#### 4.1.2目标跟踪

为了跟踪多个目标，Leal-Taix́e等人[396]和Milan等人[470]引入了第一个集中的基准MOTChallenge4。该基准包含14个具有挑战性的视频序列，是在无约束的环境下用静态和移动摄像机拍摄的。MOTChallenge结合了几个现有的多目标跟踪基准，如PETS[206]和KITTI[243]。该基准提供的公共检测器允许独立于检测器分析跟踪系统的性能。

#### 4.1.3双目和三维重建

对于双目视觉和多视角重建，有几个公开的数据集。[592, 593, 591]提出的Middlebury双目声基准5的目标是提供一个统一的测试平台，以公平地比较双目声匹配算法。创建了一个评估服务器，允许对最新的方法进行直接比较。Middlebury双目基准在促进双目视觉研究方面的成功促使Seitz等人[607]创建Middlebury多视立体(MVS)基准。该数据集由经过校准的高分辨率多视图图像和配准的3D真值模型组成，在MVS研究中发挥了关键作用。

但是，与其他数据集相比，Middlebury数据集在双目和重建方面缺乏规模和多样性(表4.1)。Jensen等人[325]的DTU MVS数据提供了在受控实验室环境中记录的124个不同场景。结合不同摄像机位置的结构光扫描获得参考数据。虽然DTU MVS数据集在使用的对象数量和它们的复杂性方面比Middlebury更多样化，但这两个数据集都没有展示真实场景的全部复杂性。


为了使多视角立体视觉走出实验室，Strecha等人[638]提出了EPFL多视角数据集8，该数据集包括5个不同建筑和一个喷泉的图像和激光雷达扫描。

最近，Scḧops等人[602]发布了ETH3D 9数据集(图4.2)，为各种室内外场景提供了高分辨率的单反图像和同步的低分辨率双目视频。他们使用高精度激光扫描仪[638]，并使用稳健的优化技术注册了所有图像。

类似地，Knapitsch等人[358]提出的Tanks and Temples10使用了高精度激光扫描仪和两台高分辨率相机(一个带全局，另一个带滚动快门)来创建室内外场景的新数据集。该数据集由14个场景组成，包括雕塑、大型车辆、房屋规模的建筑以及大型室内外场景。

对于大规模的重建，随着时间的推移，多个互联网照片集合已经被提出。最流行的集合组合在BigSFM数据集11中，包括维也纳[319]、杜布罗夫尼克[416]和罗马[140]。杜布罗夫尼克和罗马是在Flickr上找到的，而维也纳则是用校准过的相机记录下来的。除了大规模重建，这些数据集还经常用于评估闭环检测(第13.4.2节)和定位方法(第13.3节)。
 
#### 4.1.4 光流

与双目视觉类似，Baker等人[28]的Middlebury光流基准12为光流方法提供了第一个统一的测试环境和评估服务器。该基准包括非刚体运动序列、合成序列和Middlebury栓木基准的一个子集(静态场景)。对于所有非刚性序列，真值是通过跟踪喷到物体上的隐藏荧光纹理来获得的。与其他光流数据集相比(表4.1)，Middlebury流数据集规模有限，由于记录的实验室条件，缺少了复杂结构、光照变化和阴影等现实世界的挑战。此外，Middlebury只包含了不超过12个像素的小运动，不允许研究与快速运动相关的挑战。

在一般的自然场景中，由于目前还没有能够捕获光流真实的传感器，因此光流真实的获取是非常困难的。虽然[243,364]为此使用了LiDAR激光扫描仪，但它们只能获得稀疏的像素级注释，并且仅限于静态场景(仅限摄像机运动)。Janai等人[322]提出了一种从高速摄像机中获取精确参考数据的新方法，该方法通过密集采样的时空体积跟踪像素。该方法允许在具有挑战性的日常场景中获取光流地面真相，并使用运动模糊等现实效果的数据增强，以在不同条件下比较方法。Janai等[322]提供了160种动态场景的真实世界序列，其分辨率(1280×1024像素)比以前的光学数据集大得多。

光流的真值获取问题也可以通过创建合成数据集来解决。为了实现这一目标，Butler等人[92]利用了开源电影Sintel，一个动画短片。他们通过用光流真值渲染场景来创建MPI Sintel光流基准13。Sintel由1628帧组成，并提供了三种不同的数据集，这些数据集具有不同的复杂性，可以通过不同的渲染通道获得。与Middlebury类似，它们提供了一个用于比较的评估服务器

光流数据集的有限大小阻碍了深度大容量模型的训练。因此，Dosovitskiy等人[177]引入了一个简单的合成2D数据集，即在Flickr随机背景图像上渲染的飞行3D椅子，以训练卷积神经网络。由于该数据集有限的真实感不足以学习高精度模型，Mayer等人[457]提出了另一个大规模数据集，由三个具有光流真值的合成立体视频数据集组成:FlyingThings3D、Monkaa和Driving。flying things3d提供了日常的3D物体在一个随机创建的场景中沿着随机的3D轨迹飞行。受KITTI数据集的启发，driving数据集使用了与FlyingThings3D相同的池中的汽车模型，另外还使用了高度详细的树和从3D仓库中创建的模型。Monkaa是一个动画短片，类似于在MPI Sintel基准中使用的Sintel。

虽然合成光流数据集提供了大量训练深度神经网络的例子，但它们缺乏真实感，多样性有限，如表4.1所示。因此，大型合成数据集通常用于预训练，然后，预训练模型将在更小、更真实的数据集上进行微调。